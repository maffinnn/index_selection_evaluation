{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare to load table\n",
      "Loading table done\n",
      "Reading column names\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import logging\n",
    "import itertools\n",
    "import constant\n",
    "\n",
    "from selection.index_selection_evaluation import DBMSYSTEMS\n",
    "from selection.query_generator import QueryGenerator\n",
    "from selection.table_generator import TableGenerator\n",
    "from selection.what_if_index_creation import WhatIfIndexCreation\n",
    "from selection.cost_evaluation import CostEvaluation\n",
    "from selection.workload import Workload\n",
    "from selection.index import Index, index_merge\n",
    "from selection.candidate_generation import syntactically_relevant_indexes, candidates_per_query\n",
    "from selection.utils import get_utilized_indexes, indexes_by_table\n",
    "\n",
    "        \n",
    "config_file = \"config.json\"\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "dbms_class = DBMSYSTEMS[config[\"database_system\"]]\n",
    "generating_connector = dbms_class(None, autocommit=True)\n",
    "table_generator = TableGenerator(config[\"benchmark_name\"], config[\"scale_factor\"], generating_connector)\n",
    "database_name = table_generator.database_name()\n",
    "database_system = config[\"database_system\"]\n",
    "db_connector = DBMSYSTEMS[database_system](database_name)\n",
    "query_generator = QueryGenerator(\n",
    "    config[\"benchmark_name\"],\n",
    "    config[\"scale_factor\"],\n",
    "    db_connector,\n",
    "    config[\"queries\"],\n",
    "    table_generator.columns,\n",
    ")\n",
    "workload = Workload(query_generator.queries)\n",
    "cost_evaluation = CostEvaluation(db_connector, cost_estimation=\"actual_runtimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_generator.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate candidates\n",
      "Potential indexes: 55\n",
      "Potential indexes: 55\n",
      "Potential indexes: 55\n",
      "Potential indexes: 120\n",
      "Potential indexes: 120\n",
      "Potential indexes: 120\n",
      "Potential indexes: 175\n",
      "Potential indexes: 175\n",
      "Potential indexes: 175\n",
      "Potential indexes: 110\n",
      "Potential indexes: 110\n",
      "Potential indexes: 110\n",
      "Potential indexes: 62\n",
      "Potential indexes: 62\n",
      "Potential indexes: 62\n",
      "Potential indexes: 111\n",
      "Potential indexes: 111\n",
      "Potential indexes: 111\n",
      "Potential indexes: 97\n",
      "Potential indexes: 97\n",
      "Potential indexes: 97\n",
      "Potential indexes: 67\n",
      "Potential indexes: 67\n",
      "Potential indexes: 67\n",
      "Potential indexes: 81\n",
      "Potential indexes: 81\n",
      "Potential indexes: 81\n",
      "Potential indexes: 84\n",
      "Potential indexes: 84\n",
      "Potential indexes: 84\n",
      "Potential indexes: 92\n",
      "Potential indexes: 92\n",
      "Potential indexes: 92\n",
      "Potential indexes: 57\n",
      "Potential indexes: 57\n",
      "Potential indexes: 57\n",
      "Potential indexes: 104\n",
      "Potential indexes: 104\n",
      "Potential indexes: 104\n",
      "Potential indexes: 101\n",
      "Potential indexes: 101\n",
      "Potential indexes: 101\n",
      "Potential indexes: 159\n",
      "Potential indexes: 159\n",
      "Potential indexes: 159\n",
      "Potential indexes: 201\n",
      "Potential indexes: 201\n",
      "Potential indexes: 201\n",
      "Potential indexes: 205\n",
      "Potential indexes: 205\n",
      "Potential indexes: 205\n",
      "Potential indexes: 79\n",
      "Potential indexes: 79\n",
      "Potential indexes: 79\n",
      "Potential indexes: 313\n",
      "Potential indexes: 313\n",
      "Potential indexes: 313\n",
      "Potential indexes: 73\n",
      "Potential indexes: 73\n",
      "Potential indexes: 73\n",
      "Potential indexes: 263\n",
      "Potential indexes: 263\n",
      "Potential indexes: 263\n",
      "Potential indexes: 144\n",
      "Potential indexes: 144\n",
      "Potential indexes: 144\n",
      "Potential indexes: 91\n",
      "Potential indexes: 91\n",
      "Potential indexes: 91\n",
      "Potential indexes: 144\n",
      "Potential indexes: 144\n",
      "Potential indexes: 144\n",
      "Potential indexes: 56\n",
      "Potential indexes: 56\n",
      "Potential indexes: 56\n",
      "Potential indexes: 145\n",
      "Potential indexes: 145\n",
      "Potential indexes: 145\n",
      "Potential indexes: 102\n",
      "Potential indexes: 102\n",
      "Potential indexes: 102\n",
      "Potential indexes: 73\n",
      "Potential indexes: 73\n",
      "Potential indexes: 73\n",
      "Potential indexes: 82\n",
      "Potential indexes: 82\n",
      "Potential indexes: 82\n",
      "Potential indexes: 94\n",
      "Potential indexes: 94\n",
      "Potential indexes: 94\n",
      "Potential indexes: 45\n",
      "Potential indexes: 45\n",
      "Potential indexes: 45\n",
      "Potential indexes: 45\n",
      "Potential indexes: 45\n",
      "Potential indexes: 45\n",
      "Potential indexes: 178\n",
      "Potential indexes: 178\n",
      "Potential indexes: 178\n",
      "Potential indexes: 318\n",
      "Potential indexes: 318\n",
      "Potential indexes: 318\n",
      "Potential indexes: 301\n",
      "Potential indexes: 301\n",
      "Potential indexes: 301\n",
      "Potential indexes: 132\n",
      "Potential indexes: 132\n",
      "Potential indexes: 132\n",
      "Potential indexes: 77\n",
      "Potential indexes: 77\n",
      "Potential indexes: 77\n",
      "111 candidates are generated\n",
      "iteration no: 75: \n",
      "\tcurrent index config: set()\n",
      "\tnow running the 0th run on 0th index config\n",
      "\tnow running the 1th run on 0th index config\n",
      "\tnow running the 2th run on 0th index config\n",
      "\tnow running the 3th run on 0th index config\n",
      "\tcurrent index config: {I(C customer_address.ca_country,C customer_address.ca_address_sk)}\n",
      "\tnow running the 0th run on 1th index config\n",
      "\tnow running the 1th run on 1th index config\n",
      "\tnow running the 2th run on 1th index config\n",
      "\tnow running the 3th run on 1th index config\n",
      "\tcurrent index config: {I(C web_returns.wr_order_number,C web_returns.wr_item_sk), I(C web_sales.ws_sales_price,C web_sales.ws_net_profit)}\n",
      "\tnow running the 0th run on 2th index config\n",
      "\tnow running the 1th run on 2th index config\n",
      "\tnow running the 2th run on 2th index config\n",
      "\tnow running the 3th run on 2th index config\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def sample_candidates(candidates_per_query, max_config_width):\n",
    "    candidates = [[]]\n",
    "    for width in range(1, max_config_width+1):\n",
    "        possible_candidates = random.sample(candidates_per_query, width)\n",
    "        if width == 1:\n",
    "            candidates.append(possible_candidates)\n",
    "            continue\n",
    "        else:\n",
    "            # check if a config contains same column index\n",
    "            column_check = set()\n",
    "            for candidate in possible_candidates:\n",
    "                if column_check & set(candidate.columns): possible_candidates.remove(candidate)\n",
    "                else: column_check |= set(candidate.columns)\n",
    "            # keep sample until reaches the width\n",
    "            while len(possible_candidates) < width:\n",
    "                candidate = random.sample(candidates_per_query, 1)[0]\n",
    "                if column_check & set(candidate.columns): continue\n",
    "                else: \n",
    "                    column_check |= set(candidate.columns)\n",
    "                    possible_candidates.append(candidate)\n",
    "        candidates.append(possible_candidates)\n",
    "    return candidates\n",
    "\n",
    "candidates = candidates_per_query(workload,2,candidate_generator=syntactically_relevant_indexes)\n",
    "print(f\"{len(candidates)} candidates are generated\")\n",
    "number_of_actual_runs = 4\n",
    "\n",
    "filename = \"../data/DSB/dsb.csv\"\n",
    "iter = 75\n",
    "for query, candidate_per_query in zip(workload.queries[iter:], candidates[iter:]):\n",
    "    print(f\"iteration no: {iter}: \")\n",
    "    entry = [[query.nr, query.text]]\n",
    "    index_configs_per_query = sample_candidates(candidate_per_query, 4)\n",
    "    formatted_index_configs_per_query = []\n",
    "    average_execution_times_per_index_config, execution_time_list_per_config, query_plans_per_index_config = [], [], []\n",
    "    for j, index_config in enumerate(index_configs_per_query):\n",
    "        if len(index_config) == 0: formatted_index_configs_per_query.append([])\n",
    "        elif len(index_config) == 1: formatted_index_configs_per_query.append(index_config[0])\n",
    "        else: formatted_index_configs_per_query.append(tuple(index_config))\n",
    "        cost_evaluation._prepare_cost_calculation(index_config)\n",
    "        execution_time_list = []\n",
    "        for i in range(number_of_actual_runs):\n",
    "            print(f\"\\tnow running the {i}th run on {j}th index config\")\n",
    "            actual_execu_time, plan = db_connector.exec_query(query)\n",
    "            execution_time_list.append(actual_execu_time)\n",
    "        average_execution_time = sum(execution_time_list)/len(execution_time_list)\n",
    "        average_execution_times_per_index_config.append(average_execution_time)\n",
    "        execution_time_list_per_config.append(execution_time_list[1:])\n",
    "        query_plans_per_index_config.append(plan)\n",
    "        cost_evaluation.complete_cost_estimation()\n",
    "    entry.append(formatted_index_configs_per_query)\n",
    "    entry.append(average_execution_times_per_index_config)\n",
    "    entry.append(query_plans_per_index_config)\n",
    "    entry.append(execution_time_list_per_config)\n",
    "    with open(filename, \"a+\") as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(entry)\n",
    "    iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from io import StringIO  \n",
    "\n",
    "# print(\"Loading data into the tables\")\n",
    "# for filename in table_files:\n",
    "#     print(\"    Loading file {}\".format(filename))\n",
    "#     table = filename.replace(\".tbl\", \"\").replace(\".dat\", \"\")\n",
    "#     path = table_generator.directory + \"/\" + filename\n",
    "#     print(f\"    Import data of path {path}\")\n",
    "#     with open(path, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "#         for line in lines:\n",
    "#             to_write = line.rstrip('\\n')[:-1]\n",
    "#             f = StringIO(to_write+'\\n')\n",
    "#             db_connector._cursor.copy_from(f, table, sep=\"|\", null=\"\")\n",
    "#     db_connector.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "\n",
    "\n",
    "def clean_array_statistics(arr_str):\n",
    "    if arr_str == None: return []\n",
    "    str_arr = arr_str[1:-1].split(\",\")\n",
    "    print(str_arr)\n",
    "    result = []\n",
    "    for str in str_arr:\n",
    "        if str.isalpha(): return str_arr\n",
    "        value = ast.literal_eval(str.strip())\n",
    "        result.append(value)\n",
    "    return result\n",
    "    \n",
    "## generate_table_statistics\n",
    "joint_column_stats = dict()\n",
    "column_stats_path = '../data/DSB/dsbtablestats.json'\n",
    "for column in table_generator.columns:\n",
    "    column_prefix = column.name.split('_')[0]\n",
    "    table_name = constant.TPC_DS_TABLE_PREFIX[column_prefix]\n",
    "    if table_name not in joint_column_stats:\n",
    "        joint_column_stats[table_name] = dict()\n",
    "    column_stats_table = joint_column_stats[table_name]\n",
    "    column_stats = db_connector.generate_column_statistics(table_name, column.name)\n",
    "    column_stats_table[column.name] = {\n",
    "        \"attname\": column_stats[0], \n",
    "        \"null_frac\": column_stats[1],\n",
    "        \"avg_width\": column_stats[2],\n",
    "        \"n_distinct\": column_stats[3],\n",
    "        \"correlation\": column_stats[6],\n",
    "    }\n",
    "\n",
    "# save to json\n",
    "with open(column_stats_path, 'w') as outfile:\n",
    "    json.dump(joint_column_stats, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attname': 'ca_street_number', 'null_frac': 0.031166667, 'avg_width': 11, 'n_distinct': 1000.0, 'correlation': -0.00041059763}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(column_stats_path, \"r\") as f:\n",
    "    table_stats = json.load(f)\n",
    "print(table_stats[\"customer_address\"][\"ca_street_number\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siyuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
