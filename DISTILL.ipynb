{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def json_dump(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "from selection.index_selection_evaluation import DBMSYSTEMS\n",
    "from selection.query_generator import QueryGenerator\n",
    "from selection.table_generator import TableGenerator\n",
    "from selection.what_if_index_creation import WhatIfIndexCreation\n",
    "from selection.workload import Workload\n",
    "\n",
    "config_file = \"config.json\"\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbms_class = DBMSYSTEMS[config[\"database_system\"]]\n",
    "generating_connector = dbms_class(None, autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_generator = TableGenerator(\n",
    "    config[\"benchmark_name\"], config[\"scale_factor\"], generating_connector\n",
    ")\n",
    "database_name = table_generator.database_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_system = config[\"database_system\"]\n",
    "db_connector = DBMSYSTEMS[database_system](database_name)\n",
    "what_if = WhatIfIndexCreation(db_connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_generator = QueryGenerator(\n",
    "    config[\"benchmark_name\"],\n",
    "    config[\"scale_factor\"],\n",
    "    db_connector,\n",
    "    config[\"queries\"],\n",
    "    table_generator.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workload = Workload(query_generator.queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33392\n"
     ]
    }
   ],
   "source": [
    "from selection.candidate_generation import syntactically_relevant_indexes\n",
    "all_syntactically_relevant_indexes, query_config_pairs = [], []\n",
    "for query in workload.queries:\n",
    "    indexes = syntactically_relevant_indexes(query, len(query.columns))\n",
    "    all_syntactically_relevant_indexes.extend(indexes)\n",
    "    query_config_pairs.extend([(query, index) for index in indexes])\n",
    "print(len(query_config_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selection.index_selection_evaluation import IndexSelection \n",
    "\n",
    "workload_cost = None\n",
    "index_selection = IndexSelection()\n",
    "index_selection._run_algorithms(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46075564.57\n"
     ]
    }
   ],
   "source": [
    "csv_path= f\"benchmark_results/results_no_index_tpch_19_queries.csv\"\n",
    "no_index_df = pd.read_csv(csv_path, sep=';')\n",
    "workload_cost_no_index = 0\n",
    "for _, v in no_index_df.loc[0, \"q1\": \"q22\"].to_dict().items():\n",
    "    workload_cost_no_index += float(json.loads(v)[\"Cost\"])\n",
    "print(workload_cost_no_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selection.cost_evaluation import CostEvaluation\n",
    "cost_evaluation = CostEvaluation(db_connector)\n",
    "\n",
    "# workload_cost_with_index = []\n",
    "# for index in all_syntactically_relevant_indexes:\n",
    "#     cost = cost_evaluation.calculate_cost(workload, set([index]))\n",
    "#     workload_cost_with_index.append(round(cost, 2))\n",
    "#     cost_evaluation._unsimulate_or_drop_index(index)\n",
    "\n",
    "# print(workload_cost_with_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYISCAL_TO_LOGICAL_OPERATOR_MAP = {\n",
    "    \"Seq Scan\": \"Scan\",\n",
    "    \"Bitmap Index Scan\": \"Scan\",\n",
    "    \"Bitmap Heap Scan\": \"Scan\",\n",
    "    \"Index Scan\": \"Scan\",\n",
    "    \"Index Only Scan\": \"Scan\",\n",
    "    \"Sort\": \"Sort\",\n",
    "    \"Hash Join\": \"Join\",\n",
    "    \"Merge Join\": \"Join\",\n",
    "    \"Nested Loop\": \"Join\",\n",
    "    \"Aggregate\": \"Aggregate\",\n",
    "    \"Gather Merge\": \"\",\n",
    "    \"Gather\": \"\",\n",
    "    \"BitmapOr\": \"\",\n",
    "    \"Limit\": \"\",\n",
    "    \"Hash\": \"\",\n",
    "}\n",
    "\n",
    "LOGICAL_OPERATORS = [\"Scan\", \"Join\", \"Aggregate\", \"Sort\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feautures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_plans_with_index, query_costs_with_index = {}, {}\n",
    "for query in workload.queries:\n",
    "    query_plan = db_connector.get_plan(query)\n",
    "    query_plans_with_index[(query, None)] = query_plan\n",
    "    query_costs_with_index[(query, None)] = db_connector.get_cost(query)\n",
    "    indexes = syntactically_relevant_indexes(query, len(query.columns))\n",
    "    for index in indexes:\n",
    "        what_if.simulate_index(index)\n",
    "        indexed_query_plan = db_connector.get_plan_with_statistics(query)\n",
    "        indexed_query_cost = db_connector.get_cost(query)\n",
    "        what_if.drop_simulated_index(index)\n",
    "        query_plans_with_index[(query,index)] = indexed_query_plan\n",
    "        query_costs_with_index[(query,index)] = indexed_query_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cardinatlity statistics\n",
    "for table in table_generator.tables:\n",
    "    row_count = db_connector.table_row_count(table.name)\n",
    "    table.set_row_count(row_count)\n",
    "    for column in table.columns:\n",
    "        card = db_connector.get_column_cardinality(column)\n",
    "        column.set_cardinality(-card * row_count if card < 0 else card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_filtering_property(query_plan):\n",
    "    if \"Filter\" in query_plan.keys():\n",
    "        return query_plan[\"Filter\"]\n",
    "    if \"Hash Cond\" in query_plan.keys():\n",
    "        return query_plan[\"Hash Cond\"]\n",
    "    if \"Join Filter\" in query_plan.keys():\n",
    "        return query_plan[\"Join Filter\"]\n",
    "    return \"\"\n",
    "\n",
    "def has_child_node(query_plan):\n",
    "    return \"Plans\" in query_plan.keys()\n",
    "\n",
    "def is_join_operator(operator):\n",
    "    return PHYISCAL_TO_LOGICAL_OPERATOR_MAP[operator] == \"Join\"\n",
    "\n",
    "def is_sort_operator(operator):\n",
    "    return PHYISCAL_TO_LOGICAL_OPERATOR_MAP[operator] == \"Sort\"\n",
    "\n",
    "def is_aggregate_operator(operator):\n",
    "    return PHYISCAL_TO_LOGICAL_OPERATOR_MAP[operator] == \"Aggregate\"\n",
    "\n",
    "def is_scan_operator(operator):\n",
    "    return PHYISCAL_TO_LOGICAL_OPERATOR_MAP[operator] == \"Scan\"\n",
    "\n",
    "def check_indexed_column_in_condition(index, condition):\n",
    "    for column in index.columns:\n",
    "        if column.name in condition:\n",
    "            return True\n",
    "\n",
    "def get_table_from_plan_node(query_plan):\n",
    "    table = \"\"\n",
    "    if \"Relation Name\" in query_plan.keys():\n",
    "        table = query_plan[\"Relation Name\"]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal 1\n",
    "def estimate_index_utility_recursive(index, original_query_plan, indexed_query_plan):\n",
    "    total_cost = 0\n",
    "    if has_child_node(original_query_plan):\n",
    "        for original_child_node, indexed_child_node in zip(indexed_query_plan[\"Plans\"], indexed_query_plan[\"Plans\"]):\n",
    "            total_cost += estimate_index_utility_recursive(index, original_child_node, indexed_child_node)\n",
    "    current_operator = indexed_query_plan[\"Node Type\"]\n",
    "    current_cost = original_query_plan[\"Total Cost\"]\n",
    "    if (condition := has_filtering_property(indexed_query_plan)) != \"\":\n",
    "        if is_join_operator(current_operator):\n",
    "            join_output_rows = indexed_query_plan[\"Plan Rows\"]\n",
    "            left_input_rows = indexed_query_plan[\"Plans\"][0][\"Plan Rows\"]\n",
    "            right_input_rows = indexed_query_plan[\"Plans\"][1][\"Plan Rows\"]\n",
    "            if check_indexed_column_in_condition(index, condition):    \n",
    "                current_cost = (1-np.sqrt(join_output_rows/(left_input_rows*right_input_rows)))*original_query_plan[\"Total Cost\"]\n",
    "        else:\n",
    "            selectivities = [indexed_query_plan[\"Plan Rows\"]/column.table.row_count for column in index.columns if column.name in condition]\n",
    "            average_selectivity = sum(selectivities)/len(selectivities) if len(selectivities) > 0 else 0\n",
    "            current_cost = (1-average_selectivity)*original_query_plan[\"Total Cost\"]\n",
    "    elif is_sort_operator(current_operator):\n",
    "        sort_conditions = indexed_query_plan[\"Sort Key\"]\n",
    "        for sort_condition in sort_conditions:\n",
    "            if check_indexed_column_in_condition(index, sort_condition):\n",
    "                current_cost = indexed_query_plan[\"Total Cost\"]\n",
    "    elif is_aggregate_operator(current_operator) and \"Group Key\" in query_plan.keys():\n",
    "        group_conditions = query_plan[\"Group Key\"]\n",
    "        for group_condition in group_conditions:\n",
    "            if check_indexed_column_in_condition(index, group_condition):\n",
    "                current_cost = indexed_query_plan[\"Total Cost\"]\n",
    "    return total_cost+current_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal 2\n",
    "def extract_shape_of_query_and_index(index, original_query_plan):\n",
    "    query_shape, index_shape = {}, []\n",
    "    _extract_query_shape(query_shape, original_query_plan)\n",
    "    _extract_index_shape(index_shape, index, original_query_plan)\n",
    "    return query_shape, index_shape\n",
    "\n",
    "\n",
    "def _extract_query_shape(query_shape, query_plan):\n",
    "    current_operator = query_plan[\"Node Type\"]\n",
    "    logical_operator = PHYISCAL_TO_LOGICAL_OPERATOR_MAP[current_operator]\n",
    "    if is_scan_operator(current_operator):\n",
    "        table = get_table_from_plan_node(query_plan)\n",
    "        if table in query_shape.keys():\n",
    "            query_shape[table].append(logical_operator)\n",
    "        else:\n",
    "            query_shape[table] = [logical_operator]\n",
    "        return table\n",
    "    \n",
    "    tables = []    \n",
    "    if has_child_node(query_plan):\n",
    "        for child_node in query_plan[\"Plans\"]:\n",
    "            table = _extract_query_shape(query_shape, child_node)\n",
    "            if table and logical_operator:\n",
    "                tables.append(table)\n",
    "                query_shape[table].append(logical_operator)\n",
    "    return tables[0] if 0<len(tables)<2 else \"\"\n",
    "    \n",
    "def _extract_index_shape(index_shape, index, query_plan):\n",
    "    current_operator = query_plan[\"Node Type\"]\n",
    "    logical_operator = PHYISCAL_TO_LOGICAL_OPERATOR_MAP[current_operator]\n",
    "    if has_child_node(query_plan):\n",
    "        for child_node in query_plan[\"Plans\"]:\n",
    "            _extract_index_shape(index_shape, index, child_node)\n",
    "            \n",
    "    if (condition := has_filtering_property(query_plan)) != \"\":\n",
    "        if check_indexed_column_in_condition(index, condition):\n",
    "            index_shape.append(logical_operator)\n",
    "    elif is_sort_operator(current_operator):\n",
    "        sort_conditions = query_plan[\"Sort Key\"]\n",
    "        for sort_condition in sort_conditions:\n",
    "            if check_indexed_column_in_condition(index, sort_condition):\n",
    "                index_shape.append(logical_operator)\n",
    "    elif is_aggregate_operator(current_operator) and \"Group Key\" in query_plan.keys():\n",
    "        aggregate_conditions = query_plan[\"Group Key\"]\n",
    "        for aggregate_condition in aggregate_conditions:\n",
    "            if check_indexed_column_in_condition(index, aggregate_condition):\n",
    "                index_shape.append(logical_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal 3\n",
    "def evaluate_operator_relevance(index, query_plan):\n",
    "    current_operator = query_plan[\"Node Type\"]\n",
    "    relevance = 0\n",
    "    if (condition := has_filtering_property(query_plan)) != \"\":\n",
    "        selectivities = [query_plan[\"Plan Rows\"]/column.table.row_count for column in index.columns if column.name in condition]\n",
    "        relevance = sum(selectivities)/len(selectivities)\n",
    "    elif is_sort_operator(current_operator) and \"Sort Key\" in query_plan:\n",
    "        densities = []\n",
    "        conditions = query_plan[\"Sort Key\"]\n",
    "        for condition in conditions:\n",
    "            for column in index.columns:\n",
    "                if column.name in condition:\n",
    "                    densities.append(column.cardinality/column.table.row_count)\n",
    "        relevance = sum(densities)/len(densities) if len(densities) > 0 else 0\n",
    "    elif is_aggregate_operator(current_operator) and \"Group Key\" in query_plan.keys():\n",
    "        densities = []\n",
    "        conditions = query_plan[\"Group Key\"]\n",
    "        for condition in conditions:\n",
    "            for column in index.columns:\n",
    "                if column.name in condition:\n",
    "                    densities.append(column.cardinality/column.table.row_count)\n",
    "        relevance = sum(densities)/len(densities) if len(densities) > 0 else 0\n",
    "    return relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'selection.dbms.postgres_dbms.PostgresDatabaseConnector'>\n"
     ]
    }
   ],
   "source": [
    "print(type(db_connector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal 4\n",
    "def get_number_of_pages(query_plan):\n",
    "    return query_plan[\"Shared Hit Blocks\"] + query_plan[\"Shared Read Blocks\"] + query_plan[\"Local Hit Blocks\"] + query_plan[\"Local Read Blocks\"]\n",
    "\n",
    "def count_clustered_index(table_name):\n",
    "    count = db_connector.count_clustered_indexes(table_name)\n",
    "    return count\n",
    "\n",
    "def use_bitmap(query_plan):\n",
    "    current_operator = query_plan[\"Node Type\"]\n",
    "    use = False\n",
    "    if is_scan_operator(current_operator):\n",
    "        use = \"Bitmap\" in current_operator\n",
    "    \n",
    "    if has_child_node(query_plan):\n",
    "        for child_node in query_plan[\"Plans\"]:\n",
    "            use |= use_bitmap(child_node)\n",
    "    return use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Limit', 'Gather', 'Nested Loop', 'BitmapOr', 'Bitmap Index Scan', 'Aggregate', 'Merge Join', 'Hash Join', 'Sort', 'Bitmap Heap Scan', 'Index Only Scan', 'Index Scan', 'Seq Scan', 'Hash', 'Gather Merge']\n"
     ]
    }
   ],
   "source": [
    "physical_operators = set()\n",
    "\n",
    "def collect_physical_operators(physical_operators, query_plan): \n",
    "    physical_operators.add(query_plan[\"Node Type\"])\n",
    "    if has_child_node(query_plan):\n",
    "        for child_node in query_plan[\"Plans\"]:\n",
    "            collect_physical_operators(physical_operators, child_node)\n",
    "            \n",
    "for _, query_plan in query_plans_with_index.items():\n",
    "    collect_physical_operators(physical_operators, query_plan) \n",
    "\n",
    "physical_operators = list(physical_operators)  \n",
    "print(physical_operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0.]]\n",
      "[array(['Aggregate', 'Scan', 'Sort'], dtype=object), array(['Aggregate', 'Join', 'Scan', 'Sort'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# create an example dataframe to work with\n",
    "df = pd.DataFrame([\n",
    "    [\"Scan\", \"Join\"],\n",
    "    [\"Scan\", \"Aggregate\"],\n",
    "    [\"Aggregate\", \"Sort\"],\n",
    "    [\"Sort\", \"Join\"],\n",
    "    [\"Aggregate\", \"Scan\"]\n",
    "], columns=[\"operator1\", \"operator2\"])\n",
    "\n",
    "# create a OneHotEncoder that ignores (0 encodes) unseen categories\n",
    "# and encode the categorical features for the example dataframe\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(df)\n",
    "print(X_encoded)\n",
    "print(encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124556\n",
      "1124556\n",
      "1124556\n",
      "1124556\n",
      "1124556\n",
      "1124556\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "feature_columns = [\"utility\", \"relevance\", \"num_pages\", \"\"]\n",
    "features = pd.DataFrame(columns=feature_columns, index=range(len(query_config_pairs)))\n",
    "\n",
    "i = 0\n",
    "for (query, index), indexed_query_plan in query_plans_with_index.items():\n",
    "    if index == None: continue\n",
    "    labels.append(query_costs_with_index[(query, index)])\n",
    "    original_query_plan = query_plans_with_index[(query, None)]\n",
    "    original_query_cost = query_costs_with_index[(query, None)]\n",
    "    feature = pd.DataFrame()\n",
    "    utility = estimate_index_utility_recursive(index, original_query_plan, indexed_query_plan)/original_query_cost\n",
    "    # # TODO: encode index_shape feature\n",
    "    query_shape, index_shape = extract_shape_of_query_and_index(index, original_query_plan)\n",
    "    relevance = evaluate_operator_relevance(index, original_query_plan)\n",
    "    num_pages = get_number_of_pages(indexed_query_plan)\n",
    "    for related_table in query_shape.keys():\n",
    "        clustered_index_count = count_clustered_index(related_table)\n",
    "    features.iloc[i][\"utility\"] = utility\n",
    "    features.iloc[i][\"relevance\"] = relevance \n",
    "    i+=1\n",
    "\n",
    "# print(features)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nation, region, part, supplier, partsupp, customer, orders, lineitem]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_generator.tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0).fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 10\n",
    "bst = lgb.train(features, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0).fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(random_state=1, max_iter=500).fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Cost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clustering according to query template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parameter_selectivity(query_plan):\n",
    "    selectivities = None\n",
    "    if (condition := has_filtering_property(query_plan)) != \"\":\n",
    "        selectivities = [query_plan[\"Plan Rows\"]/column.table.row_count for column in index.columns if column.name in condition]\n",
    "    return selectivities\n",
    "    \n",
    "\n",
    "def evaluate_configuration():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "\n",
    "# parameters\n",
    "error_threshold = 0.05\n",
    "training_sample_size_alpha = None\n",
    "training_sample_size_beta = None\n",
    "stopping_threshold = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
